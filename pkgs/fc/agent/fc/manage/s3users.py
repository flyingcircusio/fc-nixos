"""realises pending actions on S3 users based on directory data;
accountig for usage data"""

import argparse
import errno
import json
import sys
from dataclasses import dataclass
from subprocess import CalledProcessError
from typing import Optional, Tuple

import structlog
from fc.util.directory import connect
from fc.util.logging import init_logging
from fc.util.runners import run

log = structlog.get_logger()


def list_radosgw_users() -> list[str]:
    """List all uids of users known to the local radosgw"""
    return run.json.radosgw_admin("user", "list")


def accounting(location: str, dir_conn):
    """Uploads usage data from Ceph/RadosGW into the Directory"""
    users = list_radosgw_users()

    usage = dict()
    for user in users:
        stats = run.json.radosgw_admin("user", "stats", "--uid", user)
        usage[user] = str(stats["stats"]["total_bytes"])

    dir_conn.store_s3(location, usage)


@dataclass
class S3User:
    uid: str
    display_name: str
    access_key: str
    secret_key: Optional[str]

    @classmethod
    def from_radosgw(cls, radosgw_user_info):
        try:
            # we silently ignore any additional keys here, logging this case is
            # left to an explicit check method.
            main_key = radosgw_user_info["keys"][0]
            key = {
                "access_key": main_key["access_key"],
                "secret_key": main_key["secret_key"],
            }
        except IndexError:
            key = {"access_key": None, "secret_key": None}
        return cls(
            uid=radosgw_user_info["user_id"],
            display_name=radosgw_user_info["display_name"],
            **key,
        )


@dataclass
class DirectoryS3User(S3User):
    deletion_stages: list[str]

    def ensure(self, local_users: dict[str, S3User]):
        if not self.deletion_stages:
            self.ensure_exists(local_users)
        if "soft" in self.deletion_stages:
            self.ensure_no_keys()
        if "hard" in self.deletion_stages:
            self.ensure_deleted()
            local_users.pop(self.uid, None)

    def is_consistent_with_local(self, local_users) -> bool:
        mismatches: list[str] = []
        compare_properties = ("display_name", "access_key")
        local_user_data = local_users.get(self.uid, None)
        if not local_user_data:
            mismatches.append(f"- not found in local users")
        else:
            for prop in compare_properties:
                if getattr(self, prop) != getattr(local_user_data, prop):
                    mismatches.append(f"- differ in {prop}")

        # additional checks on fresh radosgw data
        radosgw_user_info = run.json.radosgw_admin(
            "user", "info", "--uid", self.uid
        )
        if (num_keys := len(radosgw_user_info["keys"])) > 1:
            # only a warning condition, not an error
            log.warn(
                f"radosgw user {self.uid} has {num_keys}, this is more then expected."
            )

        if mismatches:
            # FIXME: could we provide the error list directly to structlog?
            log.error(
                f"User data mismatch for {self.uid}:\n"
                + "\n\t".join(mismatches)
            )
            return False
        else:
            return True

    def ensure_exists(self, local_users: dict[str, S3User]):
        """Ensures that a radosgw user with the desired properties and keys exists.
        Called upon user creation, as well as when rotating key or information.
        """

        if self.uid not in local_users:
            if not self.secret_key:
                log.warn(
                    "user create: no secret key provided, user is created with"
                    " an autogenerated secret."
                )
            radosgw_info = run.json.radosgw_admin(
                # fmt: off
                "user", "create",
                "--uid", self.uid,
                "--display-name", self.display_name,
                # Security Warning: by passing around the keys as command line
                # arguments, we potentially leak them via ps/ proc. This is
                # acceptable for now, as ceph hosts are accessible to admins only.
                # A preferential alternative would be the ability for `radosgw-admin`
                # to read from env variables. There's also the admin RESTful API of
                # radosgw, unfortunately that's based on S3 authentication logic.
                # Implementing this, e.g. via boto3, is rather complex and not a pleasure.
                "--access-key", self.access_key,
                # fmt: on
            )

        # we only modify the keys if we have the secret available
        # only modify/ add keys when we have sufficient data:
        conditional_args: list[str] = []
        if self.secret_key:
            conditional_args += ["--access-key", self.access_key]
            conditional_args += ["--secret-key", self.secret_key]
        radosgw_info = run.json.radosgw_admin(
            # fmt: off
            "user", "modify",
            "--uid", self.uid,
            "--display-name", self.display_name,
            "--access-key", self.access_key,
            *conditional_args,
            # fmt: on
        )

        # use the directory-provided user info, because that contains the single
        # access_key expected by the directory
        local_users[self.uid] = self

    def ensure_no_keys(self):
        """While other methods only manage the access key provided by the
        directory, this will remove _all_ keys to make potentially remaining
        users aware of the impending hard deletion."""

        for keydata in run.json.radosgw_admin(
            "user", "info", "--uid", self.uid
        )["keys"]:
            run.radosgw_admin("key", "rm", "access_key", keydata["access_key"])

        self.access_key = None
        self.secret_key = None

    def ensure_deleted(self):
        # --purge-keys is not really necessary, but still do it
        try:
            run.radosgw_admin(
                "user",
                "rm",
                "--uid",
                self.uid,
                "--purge-data",
                "--purge-keys",
            )
        except CalledProcessError as err:
            if err.status_code == 2 and self.uid not in list_radosgw_users():
                # potential atomicity problem, but user is gone -> all good
                pass
            else:
                raise

    @classmethod
    def from_directory(cls, uid, user_dict):

        return cls(
            uid=uid,
            display_name=user_dict["display_name"],
            access_key=user_dict["access_key"],
            secret_key=user_dict["secret_key"],
            deletion_stages=user_dict["deletion"]["stages"],
        )


class RadosgwUserManager:

    def __init__(self, directory_connection, location: str, rg: str):
        self.dir_conn = directory_connection
        self.location = location
        self.rg = rg
        self.processing_errors = False
        self.local_users = self._get_local_user_report()
        self.directory_users = self._get_directory_user_report()

    def _get_local_user_report(self) -> dict[str, S3User]:
        """Retrieve details about all locally known radosgw users for reporting to
        directory"""
        local_users = {}
        for uid in list_radosgw_users():
            radosgw_user_info = run.json.radosgw_admin(
                "user", "info", "--uid", uid
            )
            local_users[radosgw_user_info["uid"]] = S3User.from_radosgw(
                radosgw_user_info
            )

        return local_users

    def _get_directory_user_report(self) -> dict[str, DirectoryS3User]:
        """Retrieve user data from directory"""
        directory_users: dict[str, DirectoryS3User] = {}
        directory_info = self.dir_conn.list_s3_users(
            location=self.location, storage_resource_group_filter=self.rg
        )
        directory_users = {}
        for uid, user_dict in directory_info.items():
            directory_users[uid] = DirectoryS3User.from_directory(
                uid, user_dict
            )
        return directory_users

    def report_local_users_to_directory(self):
        dir_conn.update_s3_users(
            {
                uid: {
                    "display_name": user.display_name,
                    "access_key": user.access_key,
                    # directory ring0 API wants to have RG and location as explicit values
                    "location": self.location,
                    "storage_resource_group": self.rg,
                    "secret_key": None,
                }
                for uid, user in self.local_users.items()
            }
        )

    def sync_users(self):
        for uid, directory_user in self.directory_users.items():
            try:
                directory_user.ensure(self.local_users)
                directory_user.check_consistency()
            except Exception:
                # individual errors shall not block progress on all other users
                log.exception(
                    f"Encountered an error while handling {uid}, continuing:"
                )
                self.processing_errors = True

        # report all users present with uid, display_name, access_key
        self.report_local_users_to_directory()


def main() -> int:
    parser = argparse.ArgumentParser(
        description="Flying Circus S3 usage accounting"
    )
    parser.add_argument(
        "-E",
        "--enc",
        default="/etc/nixos/enc.json",
        help="Path to enc.json (default: %(default)s)",
    )

    args = parser.parse_args()
    with open(args.enc) as f:
        enc = json.load(f)

    # TODO: do we need this?
    # init_logging(
    #    context.verbose, context.logdir, show_caller_info=show_caller_info
    # )

    directory = connect(enc, ring="max")
    location = enc["parameters"]["location"]

    # first do accounting based on the existing users, might be the last time
    # in case of user deletions.
    # accounting as a first but separate step is good,
    # because we want accounting to succeed independent from any additional
    # user management failures. Users pending deletion are accounted one last
    # time, users to be created are accounted first in the next run.
    got_errors = False
    try:
        accounting(location, directory)
    except Exception:
        log.exception("Error during S3 accounting, continuing with user sync:")
        got_errors = True

    user_manager = RadosgwUserManager(
        directory, location, enc["parameters"]["rg"]
    )
    user_manager.sync_users()
    got_errors = got_errors or user_manager.processing_errors

    # on errors, the service shall return a non-zero exit code to be caught by our monitoring
    return 2 if got_errors else 0


if __name__ == "__main__":
    sys.exit(main())
