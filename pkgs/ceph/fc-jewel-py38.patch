diff --git a/man/conf.py b/man/conf.py
index 5b179911c7..c978825293 100644
--- a/man/conf.py
+++ b/man/conf.py
@@ -9,7 +9,7 @@ exclude_patterns = ['**/.#*', '**/*~']
 
 
 def _get_description(fname, base):
-    with file(fname) as f:
+    with open(fname) as f:
         one = None
         while True:
             line = f.readline().rstrip('\n')
diff --git a/src/ceph.in b/src/ceph.in
index 8ce06a7ae7..64e00ae361 100755
--- a/src/ceph.in
+++ b/src/ceph.in
@@ -122,7 +122,7 @@ import string
 import subprocess
 
 from ceph_argparse import \
-    concise_sig, descsort, parse_json_funcsigs, \
+    concise_sig, parse_json_funcsigs, \
     matchnum, validate_command, find_cmd_target, \
     send_command, json_command, run_in_thread
 
@@ -134,10 +134,8 @@ verbose = False
 cluster_handle = None
 
 # Always use Unicode (UTF-8) for stdout
-raw_stdout = sys.__stdout__
-raw_stderr = sys.__stderr__
-sys.stdout = codecs.getwriter('utf-8')(raw_stdout)
-sys.stderr = codecs.getwriter('utf-8')(raw_stderr)
+raw_stdout = sys.stdout.buffer
+raw_stderr = sys.stderr.buffer
 
 ############################################################################
 
@@ -282,7 +280,7 @@ def do_extended_help(parser, args):
         help_for_target(target=('mon', ''), partial=partial)
     return 0
 
-DONTSPLIT = string.letters + '{[<>]}'
+DONTSPLIT = string.ascii_letters + '{[<>]}'
 
 def wrap(s, width, indent):
     """
@@ -332,8 +330,6 @@ def wrap(s, width, indent):
 
             yield result
 
-    raise StopIteration
-
 def format_help(cmddict, partial=None):
     """
     Formats all the cmdsigs and helptexts from cmddict into a sorted-by-
@@ -342,7 +338,7 @@ def format_help(cmddict, partial=None):
     """
 
     fullusage = ''
-    for cmd in sorted(cmddict.itervalues(), cmp=descsort):
+    for cmd in sorted(cmddict.values(), key=lambda x:concise_sig(x['sig'])):
 
         if not cmd['help']:
             continue
@@ -925,7 +921,7 @@ def main():
             if parsed_args.output_format and \
                parsed_args.output_format.startswith('json') and \
                not compat:
-                raw_stdout.write('\n')
+                raw_stdout.write(b'\n')
 
             # if we are prettifying things, normalize newlines.  sigh.
             if suffix != '':
@@ -933,9 +929,9 @@ def main():
             if outbuf != '':
                 try:
                     # Write directly to binary stdout
-                    raw_stdout.write(prefix)
+                    print(prefix, end='')
                     raw_stdout.write(outbuf)
-                    raw_stdout.write(suffix)
+                    print(suffix, end='')
                 except IOError as e:
                     if e.errno != errno.EPIPE:
                         raise e
diff --git a/src/pybind/ceph_argparse.py b/src/pybind/ceph_argparse.py
index d8a9f4bd5e..c55ead1c65 100644
--- a/src/pybind/ceph_argparse.py
+++ b/src/pybind/ceph_argparse.py
@@ -22,12 +22,6 @@ import threading
 import uuid
 
 
-try:
-    basestring
-except NameError:
-    basestring = str
-
-
 class ArgumentError(Exception):
     """
     Something wrong with arguments
@@ -540,7 +534,7 @@ class CephPrefix(CephArgtype):
                 # but `s` could be anything passed by user.
                 s = s.decode('ascii')
         except UnicodeEncodeError:
-            raise ArgumentPrefix(u"no match for {0}".format(s))
+            raise ArgumentPrefix("no match for {0}".format(s))
         except UnicodeDecodeError:
             raise ArgumentPrefix("no match for {0}".format(s))
 
@@ -586,7 +580,7 @@ class argdesc(object):
     and will store the validated value in self.instance.val for extraction.
     """
     def __init__(self, t, name=None, n=1, req=True, **kwargs):
-        if isinstance(t, basestring):
+        if isinstance(t, str):
             self.t = CephPrefix
             self.typeargs = {'prefix': t}
             self.req = True
@@ -606,7 +600,7 @@ class argdesc(object):
     def __repr__(self):
         r = 'argdesc(' + str(self.t) + ', '
         internals = ['N', 'typeargs', 'instance', 't']
-        for (k, v) in self.__dict__.items():
+        for (k, v) in list(self.__dict__.items()):
             if k.startswith('__') or k in internals:
                 pass
             else:
@@ -614,7 +608,7 @@ class argdesc(object):
                 if k == 'n' and self.N:
                     v = 'N'
                 r += '{0}={1}, '.format(k, v)
-        for (k, v) in self.typeargs.items():
+        for (k, v) in list(self.typeargs.items()):
             r += '{0}={1}, '.format(k, v)
         return r[:-2] + ')'
 
@@ -657,14 +651,6 @@ def concise_sig(sig):
     return ' '.join([d.helpstr() for d in sig])
 
 
-def descsort(sh1, sh2):
-    """
-    sort descriptors by prefixes, defined as the concatenation of all simple
-    strings in the descriptor; this works out to just the leading strings.
-    """
-    return cmp(concise_sig(sh1['sig']), concise_sig(sh2['sig']))
-
-
 def parse_funcsig(sig):
     """
     parse a single descriptor (array of strings or dicts) into a
@@ -674,7 +660,7 @@ def parse_funcsig(sig):
     argnum = 0
     for desc in sig:
         argnum += 1
-        if isinstance(desc, basestring):
+        if isinstance(desc, str):
             t = CephPrefix
             desc = {'type': t, 'name': 'prefix', 'prefix': desc}
         else:
@@ -695,7 +681,7 @@ def parse_funcsig(sig):
                 raise JsonFormat(s)
 
         kwargs = dict()
-        for key, val in desc.items():
+        for key, val in list(desc.items()):
             if key not in ['type', 'name', 'n', 'req']:
                 kwargs[key] = val
         newsig.append(argdesc(t,
@@ -740,10 +726,10 @@ def parse_json_funcsigs(s, consumer):
     try:
         overall = json.loads(s)
     except Exception as e:
-        print >> sys.stderr, "Couldn't parse JSON {0}: {1}".format(s, e)
+        print("Couldn't parse JSON {0}: {1}".format(s, e), file=sys.stderr)
         raise e
     sigdict = {}
-    for cmdtag, cmd in overall.items():
+    for cmdtag, cmd in list(overall.items()):
         if 'sig' not in cmd:
             s = "JSON descriptor {0} has no 'sig'".format(cmdtag)
             raise JsonFormat(s)
@@ -929,10 +915,7 @@ def validate(args, signature, partial=False):
             # Have an arg; validate it
             try:
                 validate_one(myarg, desc)
-                valid = True
             except ArgumentError as e:
-                valid = False
-            if not valid:
                 # argument mismatch
                 if not desc.req:
                     # if not required, just push back; it might match
@@ -944,7 +927,7 @@ def validate(args, signature, partial=False):
                     # hm, it was required, so time to return/raise
                     if partial:
                         return d
-                    raise e
+                    raise
 
             # Whew, valid arg acquired.  Store in dict
             matchcnt += 1
@@ -958,7 +941,7 @@ def validate(args, signature, partial=False):
 
     if myargs and not partial:
         if save_exception:
-            print >> sys.stderr, save_exception[0], 'not valid: ', str(save_exception[1])
+            print(save_exception[0], 'not valid: ', str(save_exception[1]), file=sys.stderr)
         raise ArgumentError("unused arguments: " + str(myargs))
 
     # Finally, success
@@ -966,9 +949,9 @@ def validate(args, signature, partial=False):
 
 
 def cmdsiglen(sig):
-    sigdict = sig.values()
+    sigdict = list(sig.values())
     assert len(sigdict) == 1
-    some_value = next(iter(sig.values()))
+    some_value = next(iter(list(sig.values())))
     return len(some_value['sig'])
 
 
@@ -978,8 +961,7 @@ def validate_command(sigdict, args, verbose=False):
     validated against sigdict.
     """
     if verbose:
-        print >> sys.stderr, \
-            "validate_command: " + " ".join(args)
+        print("validate_command: " + " ".join(args), file=sys.stderr)
     found = []
     valid_dict = {}
     if args:
@@ -987,23 +969,21 @@ def validate_command(sigdict, args, verbose=False):
         # (so we can maybe give a more-useful error message)
         best_match_cnt = 0
         bestcmds = []
-        for cmdtag, cmd in sigdict.items():
+        for cmdtag, cmd in list(sigdict.items()):
             sig = cmd['sig']
             matched = matchnum(args, sig, partial=True)
             if (matched > best_match_cnt):
                 if verbose:
-                    print >> sys.stderr, \
-                        "better match: {0} > {1}: {2}:{3} ".\
+                    print("better match: {0} > {1}: {2}:{3} ".\
                         format(matched, best_match_cnt, cmdtag,
-                               concise_sig(sig))
+                               concise_sig(sig)), file=sys.stderr)
                 best_match_cnt = matched
                 bestcmds = [{cmdtag: cmd}]
             elif matched == best_match_cnt:
                 if verbose:
-                    print >> sys.stderr, \
-                        "equal match: {0} > {1}: {2}:{3} ".\
+                    print("equal match: {0} > {1}: {2}:{3} ".\
                         format(matched, best_match_cnt, cmdtag,
-                               concise_sig(sig))
+                               concise_sig(sig)), file=sys.stderr)
                 bestcmds.append({cmdtag: cmd})
 
         # Sort bestcmds by number of args so we can try shortest first
@@ -1011,12 +991,12 @@ def validate_command(sigdict, args, verbose=False):
         bestcmds_sorted = sorted(bestcmds, key=cmdsiglen)
 
         if verbose:
-            print >> sys.stderr, "bestcmds_sorted: "
+            print("bestcmds_sorted: ", file=sys.stderr)
             pprint.PrettyPrinter(stream=sys.stderr).pprint(bestcmds_sorted)
 
         # for everything in bestcmds, look for a true match
         for cmdsig in bestcmds_sorted:
-            for cmd in cmdsig.values():
+            for cmd in list(cmdsig.values()):
                 sig = cmd['sig']
                 try:
                     valid_dict = validate(args, sig)
@@ -1032,23 +1012,23 @@ def validate_command(sigdict, args, verbose=False):
                     # cmdsigs we'll fall out unfound; if we're not, maybe
                     # the next one matches completely.  Whine, but pass.
                     if verbose:
-                        print >> sys.stderr, 'Not enough args supplied for ', \
-                            concise_sig(sig)
+                        print('Not enough args supplied for ', \
+                            concise_sig(sig), file=sys.stderr)
                 except ArgumentError as e:
                     # Solid mismatch on an arg (type, range, etc.)
                     # Stop now, because we have the right command but
                     # some other input is invalid
-                    print >> sys.stderr, "Invalid command: ", str(e)
-                    print >> sys.stderr, concise_sig(sig), ': ', cmd['help']
+                    print("Invalid command: ", str(e), file=sys.stderr)
+                    print(concise_sig(sig), ': ', cmd['help'], file=sys.stderr)
                     return {}
             if found:
                 break
 
         if not found:
-            print >> sys.stderr, 'no valid command found; 10 closest matches:'
+            print('no valid command found; 10 closest matches:', file=sys.stderr)
             for cmdsig in bestcmds[:10]:
-                for (cmdtag, cmd) in cmdsig.iteritems():
-                    print >> sys.stderr, concise_sig(cmd['sig'])
+                for (cmdtag, cmd) in cmdsig.items():
+                    print(concise_sig(cmd['sig']), file=sys.stderr)
             return None
 
         return valid_dict
@@ -1209,8 +1189,8 @@ def send_command(cluster, target=('mon', ''), cmd=None, inbuf='', timeout=0,
             osdid = target[1]
 
             if verbose:
-                print >> sys.stderr, 'submit {0} to osd.{1}'.\
-                    format(cmd, osdid)
+                print('submit {0} to osd.{1}'.\
+                    format(cmd, osdid), file=sys.stderr)
             ret, outbuf, outs = run_in_thread(
                 cluster.osd_command, osdid, cmd, inbuf, timeout)
 
@@ -1225,15 +1205,15 @@ def send_command(cluster, target=('mon', ''), cmd=None, inbuf='', timeout=0,
                 cmddict = dict(pgid=pgid)
             cmd = [json.dumps(cmddict)]
             if verbose:
-                print >> sys.stderr, 'submit {0} for pgid {1}'.\
-                    format(cmd, pgid)
+                print('submit {0} for pgid {1}'.\
+                    format(cmd, pgid), file=sys.stderr)
             ret, outbuf, outs = run_in_thread(
                 cluster.pg_command, pgid, cmd, inbuf, timeout)
 
         elif target[0] == 'mon':
             if verbose:
-                print >> sys.stderr, '{0} to {1}'.\
-                    format(cmd, target[0])
+                print('{0} to {1}'.\
+                    format(cmd, target[0]), file=sys.stderr)
             if target[1] == '':
                 ret, outbuf, outs = run_in_thread(
                     cluster.mon_command, cmd, inbuf, timeout)
@@ -1244,8 +1224,8 @@ def send_command(cluster, target=('mon', ''), cmd=None, inbuf='', timeout=0,
             mds_spec = target[1]
 
             if verbose:
-                print >> sys.stderr, 'submit {0} to mds.{1}'.\
-                    format(cmd, mds_spec)
+                print('submit {0} to mds.{1}'.\
+                    format(cmd, mds_spec), file=sys.stderr)
 
             try:
                 from cephfs import LibCephFS
@@ -1312,4 +1292,3 @@ def json_command(cluster, target=('mon', ''), prefix=None, argdict=None,
             raise
 
     return ret, outbuf, outs
-
diff --git a/src/pybind/ceph_daemon.py b/src/pybind/ceph_daemon.py
index 638ef8978e..40e1ec91e4 100755
--- a/src/pybind/ceph_daemon.py
+++ b/src/pybind/ceph_daemon.py
@@ -36,12 +36,12 @@ def admin_socket(asok_path, cmd, format=''):
         sock = socket.socket(socket.AF_UNIX, socket.SOCK_STREAM)
         sock.connect(path)
         try:
-            sock.sendall(cmd_bytes + '\0')
+            sock.sendall(cmd_bytes + b'\0')
             len_str = sock.recv(4)
             if len(len_str) < 4:
                 raise RuntimeError("no data returned from admin socket")
             l, = struct.unpack(">I", len_str)
-            sock_ret = ''
+            sock_ret = b''
 
             got = 0
             while got < l:
@@ -55,7 +55,7 @@ def admin_socket(asok_path, cmd, format=''):
 
     try:
         cmd_json = do_sockio(asok_path,
-                             json.dumps({"prefix": "get_command_descriptions"}))
+                             json.dumps({"prefix": "get_command_descriptions"}).encode('ascii'))
     except Exception as e:
         raise RuntimeError('exception getting command descriptions: ' + str(e))
 
@@ -71,7 +71,7 @@ def admin_socket(asok_path, cmd, format=''):
         valid_dict['format'] = format
 
     try:
-        ret = do_sockio(asok_path, json.dumps(valid_dict))
+        ret = do_sockio(asok_path, json.dumps(valid_dict).encode('ascii'))
     except Exception as e:
         raise RuntimeError('exception: ' + str(e))
 
@@ -93,7 +93,7 @@ class DaemonWatcher(object):
         MAGENTA,
         CYAN,
         GRAY
-    ) = range(8)
+    ) = list(range(8))
 
     RESET_SEQ = "\033[0m"
     COLOR_SEQ = "\033[1;%dm"
@@ -174,8 +174,8 @@ class DaemonWatcher(object):
         Print a header row to `ostr`
         """
         header = ""
-        for section_name, names in self._stats.items():
-            section_width = sum([self.col_width(x)+1 for x in names.values()]) - 1
+        for section_name, names in list(self._stats.items()):
+            section_width = sum([self.col_width(x)+1 for x in list(names.values())]) - 1
             pad = max(section_width - len(section_name), 0)
             pad_prefix = pad / 2
             header += (pad_prefix * '-')
@@ -186,8 +186,8 @@ class DaemonWatcher(object):
         ostr.write(self.colorize(header, self.BLUE, True))
 
         sub_header = ""
-        for section_name, names in self._stats.items():
-            for stat_name, stat_nick in names.items():
+        for section_name, names in list(self._stats.items()):
+            for stat_name, stat_nick in list(names.items()):
                 sub_header += self.UNDERLINE_SEQ \
                               + self.colorize(
                                     stat_nick.ljust(self.col_width(stat_nick)),
@@ -203,8 +203,8 @@ class DaemonWatcher(object):
         `last_dump`.
         """
         val_row = ""
-        for section_name, names in self._stats.items():
-            for stat_name, stat_nick in names.items():
+        for section_name, names in list(self._stats.items()):
+            for stat_name, stat_nick in list(names.items()):
                 stat_type = self._schema[section_name][stat_name]['type']
                 if bool(stat_type & COUNTER):
                     n = max(dump[section_name][stat_name] -
@@ -239,8 +239,8 @@ class DaemonWatcher(object):
         # Build list of which stats we will display, based on which
         # stats have a nickname
         self._stats = defaultdict(dict)
-        for section_name, section_stats in self._schema.items():
-            for name, schema_data in section_stats.items():
+        for section_name, section_stats in list(self._schema.items()):
+            for name, schema_data in list(section_stats.items()):
                 if schema_data.get('nick'):
                     self._stats[section_name][name] = schema_data['nick']
 
diff --git a/src/pybind/ceph_rest_api.py b/src/pybind/ceph_rest_api.py
index 2dfe6b6140..8e1b9cc4c9 100755
--- a/src/pybind/ceph_rest_api.py
+++ b/src/pybind/ceph_rest_api.py
@@ -13,7 +13,7 @@ import xml.sax.saxutils
 import flask
 from ceph_argparse import \
     ArgumentError, CephPgid, CephOsdName, CephChoices, CephPrefix, \
-    concise_sig, descsort, parse_funcsig, parse_json_funcsigs, \
+    concise_sig, parse_funcsig, parse_json_funcsigs, \
     validate, json_command
 
 #
@@ -149,7 +149,7 @@ def api_setup(app, conf, cluster, clientname, clientid, args):
         maxkey = sorted(app.ceph_sigdict.keys())[-1]
         maxkey = int(maxkey.replace('cmd', ''))
         osdkey = maxkey + 1
-        for k, v in osd_sigdict.iteritems():
+        for k, v in list(osd_sigdict.items()):
             newv = v
             newv['flavor'] = 'tell'
             globk = 'cmd' + str(osdkey)
@@ -165,12 +165,12 @@ def api_setup(app, conf, cluster, clientname, clientid, args):
     # 'avail', a comma-separated list of strings of consumers that should
     #    display this command (filtered by parse_json_funcsigs() above)
     app.ceph_urls = {}
-    for cmdnum, cmddict in app.ceph_sigdict.iteritems():
+    for cmdnum, cmddict in list(app.ceph_sigdict.items()):
         cmdsig = cmddict['sig']
         flavor = cmddict.get('flavor', 'mon')
         url, params = generate_url_and_params(app, cmdsig, flavor)
         perm = cmddict['perm']
-        for k in METHOD_DICT.iterkeys():
+        for k in list(METHOD_DICT.keys()):
             if k in perm:
                 methods = METHOD_DICT[k]
         urldict = {'paramsig': params,
@@ -268,7 +268,7 @@ def show_human_help(prefix):
 
     permmap = {'r': 'GET', 'rw': 'PUT', 'rx': 'GET', 'rwx': 'PUT'}
     line = ''
-    for cmdsig in sorted(app.ceph_sigdict.itervalues(), cmp=descsort):
+    for cmdsig in sorted(iter(list(app.ceph_sigdict.values())), key=lambda x: concise_sig(x['sig'])):
         concise = concise_sig(cmdsig['sig'])
         flavor = cmdsig.get('flavor', 'mon')
         if flavor == 'tell':
@@ -300,7 +300,7 @@ def log_request():
     For every request, log it.  XXX Probably overkill for production
     '''
     app.logger.info(flask.request.url + " from " + flask.request.remote_addr + " " + flask.request.user_agent.string)
-    app.logger.debug("Accept: %s", flask.request.accept_mimetypes.values())
+    app.logger.debug("Accept: %s", list(flask.request.accept_mimetypes.values()))
 
 
 @app.route('/')
@@ -374,9 +374,9 @@ def handler(catchall_path=None, fmt=None, target=None):
 
     # Extensions override Accept: headers override defaults
     if not fmt:
-        if 'application/json' in flask.request.accept_mimetypes.values():
+        if 'application/json' in list(flask.request.accept_mimetypes.values()):
             fmt = 'json'
-        elif 'application/xml' in flask.request.accept_mimetypes.values():
+        elif 'application/xml' in list(flask.request.accept_mimetypes.values()):
             fmt = 'xml'
 
     prefix = ''
diff --git a/src/pybind/ceph_volume_client.py b/src/pybind/ceph_volume_client.py
index e571c1c04a..c38c13931e 100644
--- a/src/pybind/ceph_volume_client.py
+++ b/src/pybind/ceph_volume_client.py
@@ -23,6 +23,16 @@ import cephfs
 import rados
 
 
+def to_bytes(param):
+     '''
+     Helper method that returns byte representation of the given parameter.
+     '''
+     if isinstance(param, str):
+         return param.encode()
+     else:
+         return str(param).encode()
+
+
 class RadosError(Exception):
     """
     Something went wrong talking to Ceph with librados
@@ -181,7 +191,7 @@ class RankEvicter(threading.Thread):
     def run(self):
         try:
             self._evict()
-        except Exception, e:
+        except Exception as e:
             self.success = False
             self.exception = e
         else:
@@ -250,7 +260,7 @@ class CephFSVolumeClient(object):
         # from any other manila-share services that are loading this module.
         # We could use pid, but that's unnecessary weak: generate a
         # UUID
-        self._id = struct.unpack(">Q", uuid.uuid1().get_bytes()[0:8])[0]
+        self._id = struct.unpack(">Q", uuid.uuid1().bytes[0:8])[0]
 
         # TODO: version the on-disk structures
 
@@ -598,7 +608,7 @@ class CephFSVolumeClient(object):
             try:
                 self.fs.stat(subpath)
             except cephfs.ObjectNotFound:
-                self.fs.mkdir(subpath, 0755)
+                self.fs.mkdir(subpath, 0o755)
 
     def create_volume(self, volume_path, size=None, data_isolated=False):
         """
@@ -618,7 +628,7 @@ class CephFSVolumeClient(object):
         self._mkdir_p(path)
 
         if size is not None:
-            self.fs.setxattr(path, 'ceph.quota.max_bytes', size.__str__(), 0)
+            self.fs.setxattr(path, 'ceph.quota.max_bytes', to_bytes(size), 0)
 
         # data_isolated means create a separate pool for this volume
         if data_isolated:
@@ -630,17 +640,18 @@ class CephFSVolumeClient(object):
                 self._rados_command("mds add_data_pool", {
                     'pool': pool_name
                 })
-            self.fs.setxattr(path, 'ceph.dir.layout.pool', pool_name, 0)
+            self.fs.setxattr(path, 'ceph.dir.layout.pool', to_bytes(pool_name), 0)
 
         # enforce security isolation, use seperate namespace for this volume
         namespace = "{0}{1}".format(self.pool_ns_prefix, volume_path.volume_id)
         log.info("create_volume: {0}, using rados namespace {1} to isolate data.".format(volume_path, namespace))
-        self.fs.setxattr(path, 'ceph.dir.layout.pool_namespace', namespace, 0)
+        self.fs.setxattr(path, 'ceph.dir.layout.pool_namespace',
+                         to_bytes(namespace), 0)
 
         # Create a volume meta file, if it does not already exist, to store
         # data about auth ids having access to the volume
         fd = self.fs.open(self._volume_metadata_path(volume_path),
-                          os.O_CREAT, 0755)
+                          os.O_CREAT, 0o755)
         self.fs.close(fd)
 
         return {
@@ -743,7 +754,7 @@ class CephFSVolumeClient(object):
         on the requested path, keep checking parents until we find it.
         """
         try:
-            result = self.fs.getxattr(path, attr)
+            result = self.fs.getxattr(path, attr).decode()
             if result == "":
                 # Annoying!  cephfs gives us empty instead of an error when attr not found
                 raise cephfs.NoData()
@@ -773,7 +784,7 @@ class CephFSVolumeClient(object):
         read_bytes = self.fs.read(fd, 0, 4096 * 1024)
         self.fs.close(fd)
         if read_bytes:
-            return json.loads(read_bytes)
+            return json.loads(read_bytes.decode())
         else:
             return None
 
@@ -781,7 +792,7 @@ class CephFSVolumeClient(object):
         serialized = json.dumps(data)
         fd = self.fs.open(path, "w")
         try:
-            self.fs.write(fd, serialized, 0)
+            self.fs.write(fd, to_bytes(serialized), 0)
             self.fs.fsync(fd, 0)
         finally:
             self.fs.close(fd)
@@ -790,7 +801,7 @@ class CephFSVolumeClient(object):
         @contextmanager
         def fn():
             while(1):
-                fd = self.fs.open(path, os.O_CREAT, 0755)
+                fd = self.fs.open(path, os.O_CREAT, 0o755)
                 self.fs.flock(fd, fcntl.LOCK_EX, self._id)
 
                 # The locked file will be cleaned up sometime. It could be
@@ -1023,7 +1034,7 @@ class CephFSVolumeClient(object):
         # First I need to work out what the data pool is for this share:
         # read the layout
         pool_name = self._get_ancestor_xattr(path, "ceph.dir.layout.pool")
-        namespace = self.fs.getxattr(path, "ceph.dir.layout.pool_namespace")
+        namespace = self.fs.getxattr(path, "ceph.dir.layout.pool_namespace").decode()
 
         # Now construct auth capabilities that give the guest just enough
         # permissions to access the share
@@ -1185,7 +1196,7 @@ class CephFSVolumeClient(object):
         client_entity = "client.{0}".format(auth_id)
         path = self._get_path(volume_path)
         pool_name = self._get_ancestor_xattr(path, "ceph.dir.layout.pool")
-        namespace = self.fs.getxattr(path, "ceph.dir.layout.pool_namespace")
+        namespace = self.fs.getxattr(path, "ceph.dir.layout.pool_namespace").decode()
 
         # The auth_id might have read-only or read-write mount access for the
         # volume path.
@@ -1281,7 +1292,7 @@ class CephFSVolumeClient(object):
             if decode:
                 if outbuf:
                     try:
-                        return json.loads(outbuf)
+                        return json.loads(outbuf.decode())
                     except (ValueError, TypeError):
                         raise RadosError("Invalid JSON output for command {0}".format(argdict))
                 else:
@@ -1290,12 +1301,11 @@ class CephFSVolumeClient(object):
                 return outbuf
 
     def get_used_bytes(self, volume_path):
-        return int(self.fs.getxattr(self._get_path(volume_path), "ceph.dir.rbytes"))
+        return int(self.fs.getxattr(self._get_path(volume_path), "ceph.dir.rbytes").decode())
 
     def set_max_bytes(self, volume_path, max_bytes):
         self.fs.setxattr(self._get_path(volume_path), 'ceph.quota.max_bytes',
-                         max_bytes.__str__() if max_bytes is not None else "0",
-                         0)
+                         to_bytes(max_bytes if max_bytes else 0), 0)
 
     def _snapshot_path(self, dir_path, snapshot_name):
         return os.path.join(
@@ -1304,7 +1314,7 @@ class CephFSVolumeClient(object):
 
     def _snapshot_create(self, dir_path, snapshot_name):
         # TODO: raise intelligible exception for clusters where snaps are disabled
-        self.fs.mkdir(self._snapshot_path(dir_path, snapshot_name), 0755)
+        self.fs.mkdir(self._snapshot_path(dir_path, snapshot_name), 0o755)
 
     def _snapshot_destroy(self, dir_path, snapshot_name):
         """
diff --git a/src/pybind/cephfs/cephfs.pyx b/src/pybind/cephfs/cephfs.pyx
index 0ab2c74d1d..1b7f8125fa 100644
--- a/src/pybind/cephfs/cephfs.pyx
+++ b/src/pybind/cephfs/cephfs.pyx
@@ -15,10 +15,9 @@ import errno
 import os
 import sys
 
-# Are we running Python 2.x
-_python2 = sys.hexversion < 0x03000000
 
-if _python2:
+# Are we running Python 2.x
+if sys.version_info[0] < 3:
     str_type = basestring
 else:
     str_type = str
@@ -556,11 +555,14 @@ cdef class LibCephFS(object):
         if not dirent:
             return None
 
+        d_name = (dirent.d_name
+                  if sys.version[0:2] == '2.'
+                  else dirent.d_name.decode())
         return DirEntry(d_ino=dirent.d_ino,
                         d_off=dirent.d_off,
                         d_reclen=dirent.d_reclen,
                         d_type=dirent.d_type,
-                        d_name=dirent.d_name)
+                        d_name=d_name)
 
     def closedir(self, DirResult dir_handler):
         self.require_state("mounted")
@@ -613,7 +615,7 @@ cdef class LibCephFS(object):
 
         if not isinstance(mode, int):
             raise TypeError('mode must be an int')
-        if isinstance(flags, basestring):
+        if isinstance(flags, str):
             flags = cstr(flags, 'flags')
             cephfs_flags = 0
             if flags == '':
@@ -911,4 +913,3 @@ cdef class LibCephFS(object):
                 return (ret, b"", "")
         finally:
             free(_cmd)
-
diff --git a/src/pybind/rados/rados.pyx b/src/pybind/rados/rados.pyx
index 0bbf8ebb54..15a7d5c287 100644
--- a/src/pybind/rados/rados.pyx
+++ b/src/pybind/rados/rados.pyx
@@ -26,10 +26,9 @@ from datetime import datetime
 from functools import partial, wraps
 from itertools import chain
 
-# Are we running Python 2.x
-_python2 = sys.hexversion < 0x03000000
 
-if _python2:
+# Are we running Python 2.x
+if sys.version_info[0] < 3:
     str_type = basestring
 else:
     str_type = str
@@ -768,7 +767,7 @@ Rados object in state %s." % self.state)
         mon_id = cstr(mon_id, 'mon_id')
         cdef:
             char *_mon_id = mon_id
-            size_t outstrlen
+            size_t outstrlen = 0
             char *outstr
 
         with nogil:
@@ -1068,26 +1067,23 @@ Rados object in state %s." % self.state)
         """
         self.require_state("connected")
         cdef:
-            char *ret_buf
-            size_t buf_len = 37
-            PyObject* ret_s = NULL
+            char *ret_buf = NULL
+            size_t buf_len = 64
 
-        ret_s = PyBytes_FromStringAndSize(NULL, buf_len)
         try:
-            ret_buf = PyBytes_AsString(ret_s)
-            with nogil:
-                ret = rados_cluster_fsid(self.cluster, ret_buf, buf_len)
-            if ret < 0:
-                raise make_ex(ret, "error getting cluster fsid")
-            if ret != buf_len:
-                _PyBytes_Resize(&ret_s, ret)
-            return <object>ret_s
+            while True:
+                 ret_buf = <char *>realloc_chk(ret_buf, buf_len)
+                 with nogil:
+                     ret = rados_cluster_fsid(self.cluster, ret_buf, buf_len)
+                 if ret == -errno.ERANGE:
+                     buf_len = buf_len * 2
+                 elif ret < 0:
+                     raise make_ex(ret, "error getting cluster fsid")
+                 else:
+                     break
+            return decode_cstr(ret_buf)
         finally:
-            # We DECREF unconditionally: the cast to object above will have
-            # INCREFed if necessary. This also takes care of exceptions,
-            # including if _PyString_Resize fails (that will free the string
-            # itself and set ret_s to NULL, hence XDECREF).
-            ref.Py_XDECREF(ret_s)
+            free(ret_buf)
 
     @requires(('ioctx_name', str_type))
     def open_ioctx(self, ioctx_name):
diff --git a/src/pybind/rbd/rbd.pyx b/src/pybind/rbd/rbd.pyx
index 6e5a45b506..577d04ab35 100644
--- a/src/pybind/rbd/rbd.pyx
+++ b/src/pybind/rbd/rbd.pyx
@@ -20,6 +20,7 @@ from libc.stdint cimport *
 from libc.stdlib cimport realloc, free
 from libc.string cimport strdup
 
+import sys
 from collections import Iterable
 from datetime import datetime
 
@@ -434,7 +435,9 @@ def cstr(val, name, encoding="utf-8", opt=False):
         return None
     if isinstance(val, bytes):
         return val
-    elif isinstance(val, unicode):
+    elif isinstance(val, str):
+        return val.encode(encoding)
+    elif sys.version_info < (3, 0) and isinstance(val, unicode):
         return val.encode(encoding)
     else:
         raise InvalidArgument('%s must be a string' % name)
@@ -628,7 +631,7 @@ class RBD(object):
                     break
                 elif ret != -errno.ERANGE:
                     raise make_ex(ret, 'error listing images')
-            return [decode_cstr(name) for name in c_names[:ret].split('\0')
+            return [decode_cstr(name) for name in c_names[:ret].split(b'\0')
                     if name]
         finally:
             free(c_names)
@@ -1752,8 +1755,8 @@ written." % (self.name, ret, length))
                     raise make_ex(ret, 'error listing images')
             if ret == 0:
                 return []
-            pools = map(decode_cstr, c_pools[:pools_size - 1].split('\0'))
-            images = map(decode_cstr, c_images[:images_size - 1].split('\0'))
+            pools = map(decode_cstr, c_pools[:pools_size - 1].split(b'\0'))
+            images = map(decode_cstr, c_images[:images_size - 1].split(b'\0'))
             return list(zip(pools, images))
         finally:
             free(c_pools)
@@ -1800,9 +1803,9 @@ written." % (self.name, ret, length))
                     raise make_ex(ret, 'error listing images')
             if ret == 0:
                 return []
-            clients = map(decode_cstr, c_clients[:clients_size - 1].split('\0'))
-            cookies = map(decode_cstr, c_cookies[:cookies_size - 1].split('\0'))
-            addrs = map(decode_cstr, c_addrs[:addrs_size - 1].split('\0'))
+            clients = map(decode_cstr, c_clients[:clients_size - 1].split(b'\0'))
+            cookies = map(decode_cstr, c_cookies[:cookies_size - 1].split(b'\0'))
+            addrs = map(decode_cstr, c_addrs[:addrs_size - 1].split(b'\0'))
             return {
                 'tag'       : decode_cstr(c_tag),
                 'exclusive' : exclusive == 1,
